# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
import json
import pickle
import multiprocessing as mp
from tqdm import tqdm
from collections import defaultdict

from utils import iou_with_anchors


def load_json(file):
    with open(file) as json_file:
        data = json.load(json_file)
        return data


def getDatasetDict(cfg, split):
    annotations = {
        vdo_id: anno for vdo_id, anno in load_json(cfg.DATA.ANNOTATION_FILE)['database'].items()
        if anno['subset'] == split
    }

    return annotations


def soft_nms(df, alpha, t1, t2):
    # df: proposals generated by network;
    # alpha: alpha value of Gaussian decaying function;
    # t1, t2: threshold for soft nms.

    df = df.sort_values(by="score", ascending=False)
    tstart = list(df.xmin.values[:])
    tend = list(df.xmax.values[:])
    tscore = list(df.score.values[:])

    rstart = []
    rend = []
    rscore = []

    while len(tscore) > 1 and len(rscore) <= 1100:
        max_index = tscore.index(max(tscore))
        tmp_iou_list = iou_with_anchors(
            np.array(tstart),
            np.array(tend), tstart[max_index], tend[max_index])
        for idx in range(0, len(tscore)):
            if idx != max_index:
                tmp_iou = tmp_iou_list[idx]
                tmp_width = tend[max_index] - tstart[max_index]
                if tmp_iou > t1 + (t2 - t1) * tmp_width:
                    tscore[idx] = tscore[idx] * np.exp(-np.square(tmp_iou) / alpha)

        rstart.append(tstart[max_index])
        rend.append(tend[max_index])
        rscore.append(tscore[max_index])
        tstart.pop(max_index)
        tend.pop(max_index)
        tscore.pop(max_index)

    newDf = pd.DataFrame()
    newDf['score'] = rscore
    newDf['xmin'] = rstart
    newDf['xmax'] = rend
    return newDf


def video_post_process(cfg, video_list, video_dict, split='validation'):
    for video_name in tqdm(video_list):
        df = pd.read_csv("./outputs/BMN_results/" + video_name + ".csv")

        if len(df) > 1:
            snms_alpha = cfg.BMN.POST_PROCESS.SOFT_NMS_ALPHA
            snms_t1 = cfg.BMN.POST_PROCESS.SOFT_NMS_LOW_THRESHOLD
            snms_t2 = cfg.BMN.POST_PROCESS.SOFT_NMS_HIGH_THRESHOLD
            df = soft_nms(df, snms_alpha, snms_t1, snms_t2)

        # df = df.sort_values(by="score", ascending=False)
        video_duration = video_dict[video_name + '-0']['master_duration']
        proposal_list = []

        for j in range(min(1100, len(df))):
            tmp_proposal = {}
            tmp_proposal["score"] = df.score.values[j]
            tmp_proposal["segment"] = [max(0, df.xmin.values[j]) * video_duration,
                                       min(1, df.xmax.values[j]) * video_duration]
            proposal_list.append(tmp_proposal)

        result_dict[video_name] = proposal_list


def standardize_results(video_dict, split='validation'):
    result_dict = {}
    for video_id, results in video_dict.items():
        result_dict[video_id] = np.array([[
            r['segment'][0],
            r['segment'][1],
            r['score']] for r in results
        ])
    return result_dict


def BMN_post_processing(cfg, split='validation'):
    video_dict = getDatasetDict(cfg, split)
    video_list = list(video_dict.keys())  # [:100]
    video_groups = defaultdict(list)
    for video_name in video_list:
        video_groups[video_name.split('-')[0]].append(video_name)

    for group_name in video_groups:
        video_sequence = sorted(video_groups[group_name], key=lambda x: int(x.split('-')[-1]))
        video_df = [
            pd.read_csv('./outputs/BMN_results/' + video_name + '.csv')
            for video_name in video_sequence
        ]
        video_df = pd.concat(video_df)
        video_df.to_csv('./outputs/BMN_results/' + group_name + '.csv', index=False)

    global result_dict
    result_dict = mp.Manager().dict()

    video_list = list(video_groups.keys())
    num_videos = len(video_list)
    print('Number of videos to post-process: ', num_videos)
    num_videos_per_thread = num_videos // cfg.BMN.POST_PROCESS.NUM_THREADS
    processes = []
    for tid in range(cfg.BMN.POST_PROCESS.NUM_THREADS - 1):
        tmp_video_list = video_list[tid * num_videos_per_thread:(tid + 1) * num_videos_per_thread]
        p = mp.Process(target=video_post_process, args=(cfg, tmp_video_list, video_dict, split))
        p.start()
        processes.append(p)
    tmp_video_list = video_list[(cfg.BMN.POST_PROCESS.NUM_THREADS - 1) * num_videos_per_thread:]
    p = mp.Process(target=video_post_process, args=(cfg, tmp_video_list, video_dict, split))
    p.start()
    processes.append(p)
    for p in processes:
        p.join()

    result_dict = standardize_results(dict(result_dict))
    with open(cfg.DATA.RESULT_PATH, "wb") as f:
        pickle.dump(result_dict, f)
